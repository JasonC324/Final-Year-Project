general:
  name: Test_v2
  root_dir: null
dset:
  cls: MultilayerDataLoader
  prior_sampler:
    cls: SimpleMultilayerSampler
    kwargs:
      model_name: repeating_multilayer_abc
      max_num_layers: 30
      params:
        d_full_rel:           [1, 10]
        rel_sigmas:           [0.5, 3.0]
        d_A:                  [5, 50]
        d_B:                  [5, 50]
        d_C:                  [5, 50]
        s_A:                  [0.0, 10.0]
        s_B:                  [0.0, 10.0]
        s_C:                  [0.0, 10.0]
        r_A:                  [0.0, 8.0]
        r_B:                  [0.0, 8.0]
        r_C:                  [0.0, 8.0]
        SLD_diff_1_2:         [-4.0, 4.0]
        SLD_diff_2_3:         [-4.0, 4.0]
        dr_sigmoid_pos_AB:    [0, 30]
        dr_sigmoid_width_AB:  [1, 10]
        dr_sigmoid_pos_BC:    [0, 30]
        dr_sigmoid_width_BC:  [1, 10]
        d_sio2:               [5, 50]
        s_sio2:               [0.0, 10.0] 
        s_si:                 [0.0, 10.0]
        r_sio2:               [2.5, 4.5]
        r_si:                 [1.5, 3.0]
  q_generator:
    cls: ConstantAngle
    kwargs:
      angle_range: [1.011, 3.0, 132]
      wavelength: 0.729322
  intensity_noise:
    cls: BasicExpIntensityNoise
    kwargs:
      relative_errors: [0.05, 0.2]
      abs_errors: 1.0e-10
      consistent_rel_err: false
      logdist: true
      apply_shift: true
      scale_range: [-0.04, 0.04]
      shift_range: [-0.1, 0.2]
  q_noise:
    cls: BasicQNoiseGenerator
    kwargs:
      shift_std: 1.0e-5
      noise_std: [0., 0.001]
model:
  network:
    cls: NetworkWithPriorsConvEmb
    pretrained_name: null
    device: 'cuda'
    kwargs:
      in_channels: 1
      hidden_channels: [32, 64, 128, 256, 512]
      dim_embedding: 128
      dim_avpool: 1
      embedding_net_activation: 'gelu'
      use_batch_norm: true
      dim_out: 20
      layer_width: 512
      num_blocks: 6
      repeats_per_block: 2
      mlp_activation: 'gelu'
      dropout_rate: 0.0 
      pretrained_embedding_net: null
training:
  num_iterations: 10000
  batch_size: 4096
  lr: 1.0e-4
  grad_accumulation_steps: 1
  clip_grad_norm_max: null
  train_with_q_input: False
  update_tqdm_freq: 1
  optimizer: AdamW
  trainer_kwargs:
    optim_kwargs:
      betas: [0.9, 0.999]
      weight_decay: 0.0005
  callbacks:
    save_best_model:
      enable: true
      freq: 500
    lr_scheduler:
      cls: StepLR
      kwargs:
        step_size: 500
        gamma: 0.5
  logger:
    use_neptune: false
